# yolo_tensorrt_mlflow

-Comparing inference time of pytorch YOLOv5 model vs the NVIDIA TensorRT model
-Deploying model on MLFlow and logging the metrics

Output from the notebook- 

TensorRT Inference Time: 0.0437 seconds
ðŸš€ TensorRT Speed-up: 83.07x Faster than PyTorch
