{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100","authorship_tag":"ABX9TyPVtCS5jZ1H2F8GYCuTryk0"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BrOPJoFaYIW6","executionInfo":{"status":"ok","timestamp":1740709647202,"user_tz":420,"elapsed":15974,"user":{"displayName":"Aashish Mukund","userId":"05602305106323361582"}},"outputId":"8a985b7f-4b70-4fa6-a4eb-395f4aa7d81f"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["!pip install --upgrade ultralytics"],"metadata":{"id":"IZDwPr-6vVny"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install onnx\n","!pip install onnxruntime"],"metadata":{"id":"OYAwHZtnveka"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install mlflow"],"metadata":{"id":"Ik3J4Tx_AQEZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install pyngrok"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F26g38bwBBXz","executionInfo":{"status":"ok","timestamp":1740709739744,"user_tz":420,"elapsed":2531,"user":{"displayName":"Aashish Mukund","userId":"05602305106323361582"}},"outputId":"35dbcccf-1386-4a36-f87d-99a2341f3963"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pyngrok\n","  Downloading pyngrok-7.2.3-py3-none-any.whl.metadata (8.7 kB)\n","Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n","Downloading pyngrok-7.2.3-py3-none-any.whl (23 kB)\n","Installing collected packages: pyngrok\n","Successfully installed pyngrok-7.2.3\n"]}]},{"cell_type":"code","source":["# ✅ Install Dependencies\n","#!pip install --upgrade ultralytics\n","!apt-get install -y libnvinfer8 libnvinfer-plugin8 python3-libnvinfer\n","!pip install nvidia-pyindex && pip install nvidia-tensorrt\n","!apt-get install -y tensorrt"],"metadata":{"id":"GsZu02nK0ToI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import time\n","import onnx\n","import onnxruntime\n","import numpy as np\n","import cv2\n","import tensorrt as trt\n","import requests\n","from ultralytics import YOLO\n","\n","# ✅ Check GPU & TensorRT\n","print(\"CUDA Available:\", torch.cuda.is_available())\n","print(\"GPU:\", torch.cuda.get_device_name(0))\n","print(\"TensorRT Version:\", trt.__version__)\n","\n","# ✅ Download YOLOv8 Model\n","yolo_model = YOLO('yolov8s.pt')  # Using YOLOv8-Small\n","yolo_model.export(format=\"onnx\")  # Convert to ONNX\n","\n","# ✅ Convert ONNX to TensorRT\n","onnx_model_path = \"yolov8s.onnx\"\n","trt_engine_path = \"yolov8s.trt\"\n","\n","TRT_LOGGER = trt.Logger(trt.Logger.WARNING)\n","\n","def build_engine(onnx_path, engine_path):\n","    with trt.Builder(TRT_LOGGER) as builder, \\\n","         builder.create_network(1) as network, \\\n","         trt.OnnxParser(network, TRT_LOGGER) as parser:\n","\n","        with open(onnx_path, \"rb\") as model:\n","            parser.parse(model.read())\n","\n","        config = builder.create_builder_config()\n","        config.set_flag(trt.BuilderFlag.FP16)  # Enable FP16 Optimization\n","\n","        # 🔹 Optimization profile\n","        profile = builder.create_optimization_profile()\n","        profile.set_shape(\"input\", (1, 3, 640, 640), (1, 3, 640, 640), (1, 3, 640, 640))  # Min, Opt, Max shapes\n","        config.add_optimization_profile(profile)\n","\n","        engine = builder.build_serialized_network(network, config)\n","\n","        with open(engine_path, \"wb\") as f:\n","            f.write(engine)\n","\n","    return engine\n","\n","print(\"⚡ Converting ONNX to TensorRT...\")\n","engine = build_engine(onnx_model_path, trt_engine_path)\n","print(\"✅ TensorRT model saved at:\", trt_engine_path)\n","\n","# ✅ Load an Image for Inference (Fixed URL Handling)\n","image_url = \"https://ultralytics.com/images/zidane.jpg\"\n","\n","# 🔹 Fetch image from URL properly\n","resp = requests.get(image_url, stream=True).raw\n","image_array = np.asarray(bytearray(resp.read()), dtype=np.uint8)\n","img = cv2.imdecode(image_array, cv2.IMREAD_COLOR)\n","\n","# 🔹 Preprocess Image\n","img = cv2.resize(img, (640, 640))\n","img = img.astype(np.float32) / 255.0\n","img = np.transpose(img, (2, 0, 1))[None, :, :, :]\n","\n","# ✅ PyTorch Inference (Baseline)\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","yolo_model.to(device)\n","img_tensor = torch.tensor(img).to(device)\n","\n","start_time = time.time()\n","pred = yolo_model(img_tensor)\n","end_time = time.time()\n","pytorch_inference_time= end_time - start_time\n","print(f\"PyTorch Inference Time: {end_time - start_time:.4f} seconds\")\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GcNLrWtC3LGe","executionInfo":{"status":"ok","timestamp":1740710818659,"user_tz":420,"elapsed":343555,"user":{"displayName":"Aashish Mukund","userId":"05602305106323361582"}},"outputId":"c70f0008-eed2-4296-b3d1-5525961f9da8"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Creating new Ultralytics Settings v0.0.6 file ✅ \n","View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n","Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n","CUDA Available: True\n","GPU: NVIDIA A100-SXM4-40GB\n","TensorRT Version: 10.8.0.43\n","Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8s.pt to 'yolov8s.pt'...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 21.5M/21.5M [00:00<00:00, 138MB/s] \n"]},{"output_type":"stream","name":"stdout","text":["Ultralytics 8.3.80 🚀 Python-3.11.11 torch-2.5.1+cu124 CPU (Intel Xeon 2.20GHz)\n","YOLOv8s summary (fused): 72 layers, 11,156,544 parameters, 0 gradients, 28.6 GFLOPs\n","\n","\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'yolov8s.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 84, 8400) (21.5 MB)\n","\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirements ['onnxslim', 'onnxruntime-gpu'] not found, attempting AutoUpdate...\n","Collecting onnxslim\n","  Downloading onnxslim-0.1.48-py3-none-any.whl.metadata (4.6 kB)\n","Collecting onnxruntime-gpu\n","  Downloading onnxruntime_gpu-1.20.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n","Requirement already satisfied: onnx in /usr/local/lib/python3.11/dist-packages (from onnxslim) (1.17.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxslim) (1.13.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from onnxslim) (24.2)\n","Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime-gpu) (15.0.1)\n","Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime-gpu) (25.2.10)\n","Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.11/dist-packages (from onnxruntime-gpu) (1.26.4)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime-gpu) (4.25.6)\n","Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime-gpu) (10.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxslim) (1.3.0)\n","Downloading onnxslim-0.1.48-py3-none-any.whl (142 kB)\n","   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 142.9/142.9 kB 4.1 MB/s eta 0:00:00\n","Downloading onnxruntime_gpu-1.20.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (291.5 MB)\n","   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 291.5/291.5 MB 42.7 MB/s eta 0:00:00\n","Installing collected packages: onnxslim, onnxruntime-gpu\n","Successfully installed onnxruntime-gpu-1.20.1 onnxslim-0.1.48\n","\n","\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success ✅ 14.9s, installed 2 packages: ['onnxslim', 'onnxruntime-gpu']\n","\u001b[31m\u001b[1mrequirements:\u001b[0m ⚠️ \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n","\n","\n","\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 19...\n","\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.48...\n","\u001b[34m\u001b[1mONNX:\u001b[0m export success ✅ 16.9s, saved as 'yolov8s.onnx' (42.8 MB)\n","\n","Export complete (19.0s)\n","Results saved to \u001b[1m/content\u001b[0m\n","Predict:         yolo predict task=detect model=yolov8s.onnx imgsz=640  \n","Validate:        yolo val task=detect model=yolov8s.onnx imgsz=640 data=coco.yaml  \n","Visualize:       https://netron.app\n","⚡ Converting ONNX to TensorRT...\n","✅ TensorRT model saved at: yolov8s.trt\n","\n","0: 640x640 2 persons, 1 tie, 9.1ms\n","Speed: 0.1ms preprocess, 9.1ms inference, 251.8ms postprocess per image at shape (1, 3, 640, 640)\n","PyTorch Inference Time: 3.6286 seconds\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"mUOPiggtYG86"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["##Comparing the Inference Time with TensorRT inference time."],"metadata":{"id":"GhKW3CiM8u5T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ✅ TensorRT Inference\n","def infer_trt(engine_path, img):\n","    runtime = trt.Runtime(TRT_LOGGER)\n","    with open(engine_path, \"rb\") as f:\n","        engine = runtime.deserialize_cuda_engine(f.read())\n","\n","    context = engine.create_execution_context()\n","\n","    # ✅ Fix: Use `engine.get_binding_index()` and `engine.get_tensor_name()`\n","    binding_index = 0  # Usually input is at index 0\n","    binding_name = engine[binding_index]  # Get input tensor name\n","    input_shape = context.get_tensor_shape(binding_name)  # Corrected way\n","\n","    img = np.ascontiguousarray(img).astype(np.float32)\n","\n","    d_input = torch.from_numpy(img).cuda()\n","    d_output = torch.empty(*input_shape).cuda()\n","\n","    bindings = [int(d_input.data_ptr()), int(d_output.data_ptr())]\n","    context.execute_v2(bindings)\n","\n","    return d_output.cpu().numpy()\n","\n","\n","\n","\n","start_time = time.time()\n","trt_output = infer_trt(trt_engine_path, img)\n","end_time = time.time()\n","tensorrt_inference_time= end_time - start_time\n","print(f\"TensorRT Inference Time: {end_time - start_time:.4f} seconds\")\n","\n","# ✅ Compare Results\n","speedup = (pytorch_inference_time) / (tensorrt_inference_time)\n","print(f\"🚀 TensorRT Speed-up: {speedup:.2f}x Faster than PyTorch\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jUEcQoa85gpC","executionInfo":{"status":"ok","timestamp":1740711412606,"user_tz":420,"elapsed":43,"user":{"displayName":"Aashish Mukund","userId":"05602305106323361582"}},"outputId":"634f2f90-9879-44af-daf7-465ec640795c"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["TensorRT Inference Time: 0.0437 seconds\n","🚀 TensorRT Speed-up: 83.07x Faster than PyTorch\n"]}]}]}